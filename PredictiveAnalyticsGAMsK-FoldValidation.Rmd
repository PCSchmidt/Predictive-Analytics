---
title: "Generalized Additive Models with Cross-Fold Validation using the Advertising Data"
author: "Chris Schmidt"
date: '2019'
output:
  pdf_document: default
  word_document: default
  html_document: default
---
   

## K-Fold Validation on GAM's

This project builds generalized additive models (GAMs) using smoothing splines on the attributes of interest using the csv data in the 'Advertising.csv' file that we need to import. 

Generalized additive models extend the linear model by allowing non-linear functions of each of the variables while maintaining *additivity*. GAMs can use quantitative and qualitative responses like linear models. 

Given a multiple linear regression model

$$y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+...+\beta_px_{ip}+\epsilon_i$$

we can allow for non-linear relationships between each attribute and the response by replacing each linear component $\beta_jx_{ij}$ with a smooth non-linear function $f_j(x_{ij})$ which produces a model form

$$\begin{aligned}
&=\beta_0+\sum_{j=1}^p fj(x_{ij})+\epsilon_i\\
&=\beta_0+f_1(x_{i1})+f_2(x_{i2})+...f_p(x_{ip})+\epsilon_i\\
\end{aligned}$$

There are a number of pros and cons to GAMs that Hastie and Tibshirani discuss in their book, *The Elements of Statistical Learning* discussed in lecture that are too broad for this assignment.


### Project setup and libraries

We need the $\texttt{mgcv}$ package. 

```{r setup, include=F}

my_packages <- c("mgcv")
my_packages <- subset(my_packages, subset=!my_packages %in% rownames(installed.packages()))
if (length(my_packages)>0) install.packages(my_packages, repos = "http://cran.rstudio.com")
if (length(my_packages)==0) cat('The two packages have been installed in your computer.', '\n')
library(ISLR)
library(mgcv)
```

### The Advertisement data
##### You need save Advertising.csv in the same folder as this rmd file

```{r}
adv <- read.csv('Advertising(3).csv', header = T)
dim(adv)
```
### Fit two models to the data. Note they differ on the degrees of freedom for TV. 

Below we fit two models to the data using the **gam()** function with the smoothing spline function from the **gam** library, **s()**, and the tensor product interaction function,  **ti()** applied to the attributes of interest in each model.

```{r}
library(mgcv)

m_sr <- gam(Sales ~ s(TV) + s(Radio) + ti(TV, Radio), data = adv)

m2_sr <- gam(Sales ~ s(TV, k = 20) + s(Radio) + ti(TV, Radio), data = adv)
```


### Perform 10-fold cross validation for model m_sr and m2_sr and find which model has a smaller mean absolute error. (refer to the handout 'R code for the advertisement data.txt')

*k*-fold cross validation is a resampling technique that randomly divides the data set into k groups of observations or roughly equal size. The first fold is the validation set and the model method is run on the remaining k-1 folds of data. The $MSE_1$ (mean squared error) is computed on the observations on the held-out fold and the procedure is repeated k-times with a different held-out fold as the validation set. This generates k estimates of the test error, $MSE_1, MSE_2, ..., MSE_k$. The k-fold CV (cross validation) estimate is then generated by averaging these values.

$$CV_{(k)}=\frac{1}{k}\sum_{i=1}^k MSE_i$$

There is a bias-variance trade-off associated with the choice of *k* in k-fold cross-validation. Typically a k-value of 5 or 10 is used as these have been shown empirically to generate test-error rate estimates that do not have either high bias or high variance. 

#### When  randomly dividing the set of observations into 10 groups we use set.seed(1) to fix the random number generator so that we get the same result each time we generate the output.. 

#### 10-fold cross validation for model m_sr and MAE output

```{r}
set.seed(1)
train <- sample (200,200)
MSE <- c()
MAE <- c()
mse <- c()
mae <- c()

for (i in 1:10){
     train_data <- adv[-((i*20-19):(i*20)), ]
     test_data <- adv[((i*20-19):(i*20)), ]
     #m_sr <- gam(Sales ~ s(TV) + s(Radio) + s(Newspaper), data = train_data)
     m_sr <- gam(Sales ~ s(TV) + s(Radio) + ti(TV, Radio), data = train_data)
     mse <- c(mse, mean((predict(m_sr, newdata = test_data) - test_data$Sales)^2))
     
     test_pre <- predict(m_sr, newdata = test_data)
     mae <- c(mae, mean(abs(test_pre - test_data$Sales)))
}

MSE_m_sr <- c(MSE, mean(mse)) 
MAE_m_sr <- c(MAE, mean(mae))  
MSE_m_sr
summary(MSE_m_sr)
MAE_m_sr
summary(MAE_m_sr)
```

The mean absolute errors (MAE) for the test set for each of the 10 folds in the k-fold cross validation for model m_sr are generated below. 
```{r}
cat('The testing MAE for each of the folds in the 10-fold validation for  model m_sr are: \n',mae_m_sr = c(mae, mean(abs(test_pre - test_data$Sales))))
```

The testing set mean absolute error (MAE) across the 10 folds in the k-fold cross validation for model m_sr is generated below.
```{r}
cat('The testing MAE for the 10-fold validation for model m_sr is ', mean(MAE_m_sr), '.\n')
```
#### K-fold cross validation for model m2_sr and MAE output

```{r}
set.seed(1)
train = sample (200,200)
MSE = c()
MAE = c()
mse = c()
mae = c()

for (i in 1:10){
     train_data <- adv[-((i*20-19):(i*20)), ]
     test_data <- adv[((i*20-19):(i*20)), ]
     #m2_sr <- gam(Sales ~ s(TV) + s(Radio) + ti(TV, Radio), data = train_data)
     m2_sr <- gam(Sales ~ s(TV, k = 20) + s(Radio) + ti(TV, Radio), data = train_data)
     mse <- c(mse, mean((predict(m2_sr, newdata = test_data) - test_data$Sales)^2))
     
     test_pre <- predict(m2_sr, newdata = test_data)
     mae <- c(mae, mean(abs(test_pre - test_data$Sales)))
     
}
MSE_m2_sr = c(MSE, mean(mse))
MAE_m2_sr = c(MAE, mean(mae))
MSE_m2_sr
MAE_m2_sr
summary(MAE_m2_sr)
```

The mean absolute errors (MAE) for the test set for each of the folds in the k-fold cross validation for model m_sr are generated below. 

```{r}
cat('The testing MAE for each of the folds in the cross-fold validation for model m2_sr are: \n',mae_m2_sr = c(mae, mean(abs(test_pre - test_data$Sales))), '.\n')
```

The testing set mean absolute error (MAE) across the 10 folds in the k-fold cross validation for model m_sr is generated below.
```{r}
cat('The testing MAE for the cross-fold validation for model m2_sr is', mean(MAE_m2_sr), '.\n')
```

### Summary: The lower mean absolute error is generated by the model m2_sr. 

Model m_sr Test Dataset MAE:  0.2968779 

Model m2_sr Test Dataset MAE: 0.2872649

